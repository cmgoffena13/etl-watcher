"""restart

Revision ID: 20250908215819
Revises:
Create Date: 2025-09-08 21:58:21.516663

"""

from typing import Sequence, Union

import sqlalchemy as sa
import sqlmodel  # ADDED
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "20250908215819"
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "address_type",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column(
            "group_name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(op.f("ix_address_type_name"), "address_type", ["name"], unique=True)
    op.create_table(
        "pipeline_type",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column(
            "group_name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False
        ),
        sa.Column("timely_number", sa.Integer(), nullable=True),
        sa.Column(
            "timely_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=True,
        ),
        sa.Column(
            "mute_timely_check",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_pipeline_type_name"), "pipeline_type", ["name"], unique=True
    )
    op.create_table(
        "address",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column("address_type_id", sa.Integer(), nullable=False),
        sa.Column(
            "database_name", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "schema_name", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "table_name", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "primary_key", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "deprecated", sa.BOOLEAN(), server_default=sa.text("FALSE"), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["address_type_id"],
            ["address_type.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_address_address_type_id"), "address", ["address_type_id"], unique=False
    )
    op.create_index(op.f("ix_address_name"), "address", ["name"], unique=True)
    op.create_table(
        "pipeline",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column("pipeline_type_id", sa.Integer(), nullable=False),
        sa.Column(
            "watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "next_watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "pipeline_args", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column("last_target_insert", sa.DateTime(timezone=True), nullable=True),
        sa.Column("last_target_update", sa.DateTime(timezone=True), nullable=True),
        sa.Column("last_target_soft_delete", sa.DateTime(timezone=True), nullable=True),
        sa.Column("timely_number", sa.Integer(), nullable=True),
        sa.Column(
            "timely_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=True,
        ),
        sa.Column(
            "mute_timely_check",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column(
            "load_lineage",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column(
            "active", sa.Boolean(), server_default=sa.text("TRUE"), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["pipeline_type_id"],
            ["pipeline_type.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_pipeline_name_includes",
        "pipeline",
        ["name"],
        unique=True,
        postgresql_include=["load_lineage", "active"],
    )
    op.create_index(
        op.f("ix_pipeline_pipeline_type_id"),
        "pipeline",
        ["pipeline_type_id"],
        unique=False,
    )
    op.create_table(
        "address_lineage",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("source_address_id", sa.Integer(), nullable=False),
        sa.Column("target_address_id", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.ForeignKeyConstraint(
            ["source_address_id"],
            ["address.id"],
        ),
        sa.ForeignKeyConstraint(
            ["target_address_id"],
            ["address.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_address_lineage_pipeline", "address_lineage", ["pipeline_id"], unique=False
    )
    op.create_index(
        "ix_address_lineage_source_target",
        "address_lineage",
        ["source_address_id", "target_address_id"],
        unique=True,
    )
    op.create_index(
        "ix_address_lineage_target_source",
        "address_lineage",
        ["target_address_id", "source_address_id"],
        unique=True,
    )
    op.create_table(
        "address_lineage_closure",
        sa.Column("source_address_id", sa.Integer(), nullable=False),
        sa.Column("target_address_id", sa.Integer(), nullable=False),
        sa.Column("depth", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["source_address_id"],
            ["address.id"],
        ),
        sa.ForeignKeyConstraint(
            ["target_address_id"],
            ["address.id"],
        ),
        sa.PrimaryKeyConstraint("source_address_id", "target_address_id"),
    )
    op.create_index(
        "ix_address_lineage_closure_depth_source",
        "address_lineage_closure",
        ["source_address_id", "depth"],
        unique=False,
        postgresql_include=["target_address_id"],
    )
    op.create_index(
        "ix_address_lineage_closure_depth_target",
        "address_lineage_closure",
        ["target_address_id", "depth"],
        unique=False,
        postgresql_include=["source_address_id"],
    )
    op.create_table(
        "pipeline_execution",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("parent_id", sa.Integer(), nullable=True),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("start_date", sa.DateTime(timezone=True), nullable=False),
        sa.Column("end_date", sa.DateTime(timezone=True), nullable=True),
        sa.Column("duration_seconds", sa.Integer(), nullable=True),
        sa.Column(
            "completed_successfully",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column("inserts", sa.Integer(), nullable=True),
        sa.Column("updates", sa.Integer(), nullable=True),
        sa.Column("soft_deletes", sa.Integer(), nullable=True),
        sa.Column("total_rows", sa.Integer(), nullable=True),
        sa.Column("full_load", sa.Boolean(), nullable=True),
        sa.Column(
            "watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "next_watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_pipeline_execution_end_date_filter",
        "pipeline_execution",
        ["end_date"],
        unique=False,
        postgresql_where=sa.text("end_date IS NOT NULL"),
    )
    op.create_table(
        "timeliness_pipeline_execution_log",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("pipeline_execution_id", sa.Integer(), nullable=False),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("duration_seconds", sa.Integer(), nullable=False),
        sa.Column("seconds_threshold", sa.Integer(), nullable=False),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_execution_id"],
            ["pipeline_execution.id"],
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_timeliness_pipeline_execution_log_pipeline_execution_id"),
        "timeliness_pipeline_execution_log",
        ["pipeline_execution_id"],
        unique=True,
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(
        op.f("ix_timeliness_pipeline_execution_log_pipeline_execution_id"),
        table_name="timeliness_pipeline_execution_log",
    )
    op.drop_table("timeliness_pipeline_execution_log")
    op.drop_index(
        "ix_pipeline_execution_end_date_filter",
        table_name="pipeline_execution",
        postgresql_where=sa.text("end_date IS NOT NULL"),
    )
    op.drop_table("pipeline_execution")
    op.drop_index(
        "ix_address_lineage_closure_depth_target",
        table_name="address_lineage_closure",
        postgresql_include=["source_address_id"],
    )
    op.drop_index(
        "ix_address_lineage_closure_depth_source",
        table_name="address_lineage_closure",
        postgresql_include=["target_address_id"],
    )
    op.drop_table("address_lineage_closure")
    op.drop_index("ix_address_lineage_target_source", table_name="address_lineage")
    op.drop_index("ix_address_lineage_source_target", table_name="address_lineage")
    op.drop_index("ix_address_lineage_pipeline", table_name="address_lineage")
    op.drop_table("address_lineage")
    op.drop_index(op.f("ix_pipeline_pipeline_type_id"), table_name="pipeline")
    op.drop_index(
        "ix_pipeline_name_includes",
        table_name="pipeline",
        postgresql_include=["load_lineage", "active"],
    )
    op.drop_table("pipeline")
    op.drop_index(op.f("ix_address_name"), table_name="address")
    op.drop_index(op.f("ix_address_address_type_id"), table_name="address")
    op.drop_table("address")
    op.drop_index(op.f("ix_pipeline_type_name"), table_name="pipeline_type")
    op.drop_table("pipeline_type")
    op.drop_index(op.f("ix_address_type_name"), table_name="address_type")
    op.drop_table("address_type")
    # ### end Alembic commands ###
