"""initial

Revision ID: 20250930170804
Revises:
Create Date: 2025-09-30 17:08:07.084842

"""

from typing import Sequence, Union

import sqlalchemy as sa
import sqlmodel  # ADDED
from alembic import op
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = "20250930170804"
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "address_type",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column(
            "group_name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_address_type_name_includes",
        "address_type",
        ["name"],
        unique=True,
        postgresql_include=["id"],
    )
    op.create_table(
        "pipeline_type",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column("freshness_number", sa.Integer(), nullable=True),
        sa.Column(
            "freshness_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=True,
        ),
        sa.Column(
            "mute_freshness_check",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column("timeliness_number", sa.Integer(), nullable=True),
        sa.Column(
            "timeliness_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=True,
        ),
        sa.Column(
            "mute_timeliness_check",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_pipeline_type_name_includes",
        "pipeline_type",
        ["name"],
        unique=True,
        postgresql_include=["id"],
    )
    op.create_table(
        "address",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column("address_type_id", sa.Integer(), nullable=False),
        sa.Column(
            "database_name", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "schema_name", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "table_name", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "primary_key", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "deprecated", sa.BOOLEAN(), server_default=sa.text("FALSE"), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["address_type_id"],
            ["address_type.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        op.f("ix_address_address_type_id"), "address", ["address_type_id"], unique=False
    )
    op.create_index(
        "ix_address_name_includes",
        "address",
        ["name"],
        unique=True,
        postgresql_include=["id"],
    )
    op.create_table(
        "pipeline",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("name", sqlmodel.sql.sqltypes.AutoString(length=150), nullable=False),
        sa.Column("pipeline_type_id", sa.Integer(), nullable=False),
        sa.Column(
            "watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "next_watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "pipeline_metadata", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column("last_target_insert", sa.DateTime(timezone=True), nullable=True),
        sa.Column("last_target_update", sa.DateTime(timezone=True), nullable=True),
        sa.Column("last_target_soft_delete", sa.DateTime(timezone=True), nullable=True),
        sa.Column("freshness_number", sa.Integer(), nullable=True),
        sa.Column(
            "freshness_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=True,
        ),
        sa.Column(
            "mute_freshness_check",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column("timeliness_number", sa.Integer(), nullable=True),
        sa.Column(
            "timeliness_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=True,
        ),
        sa.Column(
            "mute_timeliness_check",
            sa.Boolean(),
            server_default=sa.text("FALSE"),
            nullable=False,
        ),
        sa.Column(
            "load_lineage", sa.Boolean(), server_default=sa.text("TRUE"), nullable=False
        ),
        sa.Column(
            "active", sa.Boolean(), server_default=sa.text("TRUE"), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["pipeline_type_id"],
            ["pipeline_type.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_pipeline_name_includes",
        "pipeline",
        ["name"],
        unique=True,
        postgresql_include=["load_lineage", "active", "id"],
    )
    op.create_index(
        "ix_pipeline_pipeline_type_id_includes",
        "pipeline",
        ["pipeline_type_id"],
        unique=False,
        postgresql_include=["id"],
    )
    op.create_table(
        "address_lineage",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("source_address_id", sa.Integer(), nullable=False),
        sa.Column("target_address_id", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.ForeignKeyConstraint(
            ["source_address_id"],
            ["address.id"],
        ),
        sa.ForeignKeyConstraint(
            ["target_address_id"],
            ["address.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_address_lineage_pipeline", "address_lineage", ["pipeline_id"], unique=False
    )
    op.create_index(
        "ix_address_lineage_source_target",
        "address_lineage",
        ["source_address_id", "target_address_id"],
        unique=True,
    )
    op.create_index(
        "ix_address_lineage_target_source",
        "address_lineage",
        ["target_address_id", "source_address_id"],
        unique=True,
    )
    op.create_table(
        "address_lineage_closure",
        sa.Column("source_address_id", sa.Integer(), nullable=False),
        sa.Column("target_address_id", sa.Integer(), nullable=False),
        sa.Column("depth", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["source_address_id"],
            ["address.id"],
        ),
        sa.ForeignKeyConstraint(
            ["target_address_id"],
            ["address.id"],
        ),
        sa.PrimaryKeyConstraint("source_address_id", "target_address_id"),
    )
    op.create_index(
        "ix_address_lineage_closure_depth_source",
        "address_lineage_closure",
        ["source_address_id", "depth"],
        unique=False,
        postgresql_include=["target_address_id"],
    )
    op.create_index(
        "ix_address_lineage_closure_depth_target",
        "address_lineage_closure",
        ["target_address_id", "depth"],
        unique=False,
        postgresql_include=["source_address_id"],
    )
    op.create_table(
        "anomaly_detection_rule",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column(
            "metric_field",
            sa.Enum(
                "DURATION_SECONDS",
                "INSERTS",
                "UPDATES",
                "SOFT_DELETES",
                "TOTAL_ROWS",
                "THROUGHPUT",
                name="anomalymetricfieldenum",
            ),
            nullable=False,
        ),
        sa.Column("z_threshold", sa.DECIMAL(precision=4, scale=2), nullable=True),
        sa.Column("lookback_days", sa.Integer(), nullable=False),
        sa.Column("minimum_executions", sa.Integer(), nullable=False),
        sa.Column(
            "active", sa.Boolean(), server_default=sa.text("TRUE"), nullable=False
        ),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.Column("updated_at", sa.DateTime(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_anomaly_detection_rule_composite_key",
        "anomaly_detection_rule",
        ["pipeline_id", "metric_field"],
        unique=True,
        postgresql_include=["id"],
    )
    op.create_index(
        "ix_anomaly_detection_rule_pipeline_id",
        "anomaly_detection_rule",
        ["pipeline_id", "active"],
        unique=False,
        postgresql_include=["id"],
    )
    op.create_table(
        "freshness_pipeline_log",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("last_dml_timestamp", sa.DateTime(timezone=True), nullable=True),
        sa.Column("evaluation_timestamp", sa.DateTime(timezone=True), nullable=True),
        sa.Column("freshness_number", sa.Integer(), nullable=False),
        sa.Column(
            "freshness_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=False,
        ),
        sa.Column("used_child_config", sa.Boolean(), nullable=False),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_freshness_pipeline_log_covering",
        "freshness_pipeline_log",
        ["last_dml_timestamp", "pipeline_id"],
        unique=True,
    )
    op.create_table(
        "pipeline_execution",
        sa.Column("id", sa.BigInteger(), nullable=False),
        sa.Column("parent_id", sa.Integer(), nullable=True),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("start_date", sa.DateTime(timezone=True), nullable=False),
        sa.Column("date_recorded", sa.Date(), nullable=False),
        sa.Column("hour_recorded", sa.Integer(), nullable=False),
        sa.Column("end_date", sa.DateTime(timezone=True), nullable=True),
        sa.Column("duration_seconds", sa.Integer(), nullable=True),
        sa.Column("completed_successfully", sa.Boolean(), nullable=True),
        sa.Column("inserts", sa.Integer(), nullable=True),
        sa.Column("updates", sa.Integer(), nullable=True),
        sa.Column("soft_deletes", sa.Integer(), nullable=True),
        sa.Column("total_rows", sa.Integer(), nullable=True),
        sa.Column("full_load", sa.Boolean(), nullable=True),
        sa.Column(
            "watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "next_watermark", sqlmodel.sql.sqltypes.AutoString(length=50), nullable=True
        ),
        sa.Column(
            "execution_metadata", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column(
            "anomaly_flags", postgresql.JSONB(astext_type=sa.Text()), nullable=True
        ),
        sa.Column("throughput", sa.DECIMAL(precision=12, scale=4), nullable=True),
        sa.CheckConstraint("end_date IS NULL OR end_date > start_date"),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "ix_pipeline_execution_date_recorded_seek",
        "pipeline_execution",
        ["date_recorded", "pipeline_id"],
        unique=False,
        postgresql_include=["id"],
    )
    op.create_index(
        "ix_pipeline_execution_hour_recorded",
        "pipeline_execution",
        ["pipeline_id", "hour_recorded", "end_date"],
        unique=False,
        postgresql_include=["completed_successfully", "id"],
        postgresql_where=sa.text("end_date IS NOT NULL"),
    )
    op.create_index(
        "ix_pipeline_execution_start_date",
        "pipeline_execution",
        ["start_date"],
        unique=False,
        postgresql_include=["id"],
    )
    op.create_table(
        "anomaly_detection_result",
        sa.Column("pipeline_execution_id", sa.BigInteger(), nullable=False),
        sa.Column("rule_id", sa.Integer(), nullable=False),
        sa.Column("violation_value", sa.DECIMAL(precision=12, scale=4), nullable=True),
        sa.Column("z_score", sa.DECIMAL(precision=12, scale=4), nullable=True),
        sa.Column("historical_mean", sa.DECIMAL(precision=12, scale=4), nullable=True),
        sa.Column(
            "std_deviation_value", sa.DECIMAL(precision=12, scale=4), nullable=True
        ),
        sa.Column("z_threshold", sa.DECIMAL(precision=12, scale=4), nullable=True),
        sa.Column(
            "threshold_min_value", sa.DECIMAL(precision=12, scale=4), nullable=True
        ),
        sa.Column(
            "threshold_max_value", sa.DECIMAL(precision=12, scale=4), nullable=True
        ),
        sa.Column("context", postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.Column(
            "detected_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_execution_id"],
            ["pipeline_execution.id"],
        ),
        sa.ForeignKeyConstraint(
            ["rule_id"],
            ["anomaly_detection_rule.id"],
        ),
        sa.PrimaryKeyConstraint("pipeline_execution_id", "rule_id"),
    )
    op.create_table(
        "timeliness_pipeline_execution_log",
        sa.Column("pipeline_execution_id", sa.BigInteger(), nullable=False),
        sa.Column("pipeline_id", sa.Integer(), nullable=False),
        sa.Column("duration_seconds", sa.Integer(), nullable=False),
        sa.Column("seconds_threshold", sa.Integer(), nullable=False),
        sa.Column(
            "execution_status", sqlmodel.sql.sqltypes.AutoString(), nullable=False
        ),
        sa.Column("timely_number", sa.Integer(), nullable=False),
        sa.Column(
            "timely_datepart",
            sa.Enum(
                "MINUTE", "HOUR", "DAY", "WEEK", "MONTH", "YEAR", name="datepartenum"
            ),
            nullable=False,
        ),
        sa.Column("used_child_config", sa.Boolean(), nullable=False),
        sa.Column(
            "created_at",
            sa.DateTime(timezone=True),
            server_default=sa.text("CURRENT_TIMESTAMP"),
            nullable=False,
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_execution_id"],
            ["pipeline_execution.id"],
        ),
        sa.ForeignKeyConstraint(
            ["pipeline_id"],
            ["pipeline.id"],
        ),
        sa.PrimaryKeyConstraint("pipeline_execution_id"),
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table("timeliness_pipeline_execution_log")
    op.drop_table("anomaly_detection_result")
    op.drop_index(
        "ix_pipeline_execution_start_date",
        table_name="pipeline_execution",
        postgresql_include=["id"],
    )
    op.drop_index(
        "ix_pipeline_execution_hour_recorded",
        table_name="pipeline_execution",
        postgresql_include=["completed_successfully", "id"],
        postgresql_where=sa.text("end_date IS NOT NULL"),
    )
    op.drop_index(
        "ix_pipeline_execution_date_recorded_seek",
        table_name="pipeline_execution",
        postgresql_include=["id"],
    )
    op.drop_table("pipeline_execution")
    op.drop_index(
        "ix_freshness_pipeline_log_covering", table_name="freshness_pipeline_log"
    )
    op.drop_table("freshness_pipeline_log")
    op.drop_index(
        "ix_anomaly_detection_rule_pipeline_id",
        table_name="anomaly_detection_rule",
        postgresql_include=["id"],
    )
    op.drop_index(
        "ix_anomaly_detection_rule_composite_key",
        table_name="anomaly_detection_rule",
        postgresql_include=["id"],
    )
    op.drop_table("anomaly_detection_rule")
    op.drop_index(
        "ix_address_lineage_closure_depth_target",
        table_name="address_lineage_closure",
        postgresql_include=["source_address_id"],
    )
    op.drop_index(
        "ix_address_lineage_closure_depth_source",
        table_name="address_lineage_closure",
        postgresql_include=["target_address_id"],
    )
    op.drop_table("address_lineage_closure")
    op.drop_index("ix_address_lineage_target_source", table_name="address_lineage")
    op.drop_index("ix_address_lineage_source_target", table_name="address_lineage")
    op.drop_index("ix_address_lineage_pipeline", table_name="address_lineage")
    op.drop_table("address_lineage")
    op.drop_index(
        "ix_pipeline_pipeline_type_id_includes",
        table_name="pipeline",
        postgresql_include=["id"],
    )
    op.drop_index(
        "ix_pipeline_name_includes",
        table_name="pipeline",
        postgresql_include=["load_lineage", "active", "id"],
    )
    op.drop_table("pipeline")
    op.drop_index(
        "ix_address_name_includes", table_name="address", postgresql_include=["id"]
    )
    op.drop_index(op.f("ix_address_address_type_id"), table_name="address")
    op.drop_table("address")
    op.drop_index(
        "ix_pipeline_type_name_includes",
        table_name="pipeline_type",
        postgresql_include=["id"],
    )
    op.drop_table("pipeline_type")
    op.drop_index(
        "ix_address_type_name_includes",
        table_name="address_type",
        postgresql_include=["id"],
    )
    op.drop_table("address_type")
    # ### end Alembic commands ###
